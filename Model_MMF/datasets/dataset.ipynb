{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa820fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from mmf.common.sample import Sample\n",
    "from mmf.datasets.mmf_dataset import MMFDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69d3f38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HatefulMemesFeaturesDataset(MMFDataset):\n",
    "    def __init__(self, config, *args, dataset_name=\"hateful_memes\", **kargs):\n",
    "        super().__init__(dataset_name, config, *args, **kargs)       \n",
    "        assert(\n",
    "            self._use_features\n",
    "        ), \"config's 'use_features' must be true to use img dataset\"        \n",
    "        self.is_multilabel = self.config.get(\"is_multilable\", False)\n",
    "        \n",
    "    def preprocess_sample_info(self, sample_info):\n",
    "        image_path = sample_info['img'] \n",
    "        # img/1234.png -> 1234\n",
    "        feature_path = image_path.split('/')[-1].split('.')[0]\n",
    "        # add the feature_path key to sample_info for feature_database access\n",
    "        sample_info['feature_path'] = f\"{feature_path}.npy\" \n",
    "        return sample_info\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample_info = self.annotation_db[index] #MMFDataset has .annotation_db field\n",
    "        sample_info = self.preprocess_sample_info(sample_info)\n",
    "        \n",
    "        current_sample = Sample()\n",
    "        \n",
    "        # Haoyun: where is .text_processor??\n",
    "        processed_text = self.text_processor({\"text\": sample_info[\"text\"]})\n",
    "        current_sample.text = processed_text[\"text\"]\n",
    "        # Haoyun: where is .update??\n",
    "        if \"input_ids\" in processed_text:\n",
    "            current_sample.update(processed_text)\n",
    "            \n",
    "        current_sample.id = torch.tensor(int(sample_info['id']), dtype=torch.int)    \n",
    "        \n",
    "        features = self.features_db.get(sample_info)\n",
    "        if hasattr(self, \"transformer_bbox_processor\"):\n",
    "            features[\"image_info_0\"] = self.transformer_bbox_processor(\n",
    "                features[\"image_info_0\"]\n",
    "            )\n",
    "        current_sample.update(features)\n",
    "        \n",
    "        if \"label\" in sample_info:\n",
    "            current_sample.targets = torch.tensor(sample_info[\"label\"], dtype=torch.long)\n",
    "        \n",
    "        return current_sample\n",
    "    \n",
    "    def format_for_prediction(self, report):\n",
    "        if self.is_multilabel:\n",
    "            return generate_multilabel_prediction(report)\n",
    "        else:\n",
    "            return generate_binary_prediction(report)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3df88976",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HatefulMemesImageDataset(MMFDataset):\n",
    "    def __init__(self, config, *args, dataset_name=\"hateful_memes\", **kargs):\n",
    "        super().__init__(dataset_name, config, *args, **kargs)\n",
    "        assert(\n",
    "            self._use_features\n",
    "        ), \"config's 'use_features' must be true to use img dataset\"        \n",
    "        self.is_multilabel = self.config.get(\"is_multilable\", False)\n",
    "        \n",
    "    def init_processors(self):\n",
    "        super().init_processors()\n",
    "        self.image_db.transfrom = self.image_processor\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        sample_info = self.annotation_db[index]\n",
    "        current_sample = Sample()\n",
    "        \n",
    "        processed_text = self.text_processor({\"text\": sample_info[\"text\"]})\n",
    "        current_sample.text = processed_text[\"text\"]\n",
    "        if \"input_ids\" in processed_text:\n",
    "            current_sample.update(processed_text) \n",
    "            \n",
    "        current_sample.id = torch.tensor(int(sample_info['id']), dtype=torch.int)   \n",
    "        \n",
    "        current_sample.image = self.image_db[index][\"images\"][0]\n",
    "        \n",
    "        if \"label\" in sample_info:\n",
    "            current_sample.targets = torch.tensor(sample_info[\"label\"], dtype=torch.long)\n",
    "        \n",
    "        return current_sample   \n",
    "    \n",
    "    def format_for_prediction(self, report):\n",
    "        if self.is_multilabel:\n",
    "            return generate_multilabel_prediction(report)\n",
    "        else:\n",
    "            return generate_binary_prediction(report)  \n",
    "        \n",
    "    def visualize(self, num_samples=1, use_transforms=False, *args, **kargs):\n",
    "        image_paths = []\n",
    "        random_samples = np.random_randint(0, len(self), size=num_samples)\n",
    "        \n",
    "        for index in random_samples:\n",
    "            image_paths.append(self.annotation_db[index]['img'])\n",
    "            \n",
    "        images = self.image_db_from_path(image_paths, use_transfomrs=use_transforms)\n",
    "        visualize_images(images[\"images\"], *args, **kargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96156636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_binary_prediction(report):\n",
    "    scores = torch.nn.functional.softmax(report.scores, dim=1)\n",
    "    _, labels = torch.max(scores, 1)\n",
    "    probabilities = scores[:, 1]\n",
    "    \n",
    "    predictions = []\n",
    "    for index, image_id in enumerate(report.id):\n",
    "        prob = probabilities[index].items()\n",
    "        label = labels[index].item()\n",
    "        predictions.append({\"id\": image_id.item(), \n",
    "                            \"prob\": prob, \n",
    "                            \"label\": label})\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e20992c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_multilabel_prediction(report):\n",
    "    scores = torch.sigmoid(report.scores)\n",
    "    return [\n",
    "        {\"id\": image_id.item(), \"scores\": scores[index].tolist()}\n",
    "        for index, imgae_id in enumerate(report.id)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82922dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#two funcs mixed up???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e968b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MMF_Env]",
   "language": "python",
   "name": "conda-env-MMF_Env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
