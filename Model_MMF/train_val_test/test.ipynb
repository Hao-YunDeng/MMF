{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0396108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmf.utils.build import build_processors\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.datasets.folder as tv_helpers\n",
    "\n",
    "from mmf.common.sample import Sample, SampleList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a121d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build config, processors and model\n",
    "\n",
    "\n",
    "# Build configuration\n",
    "dataset_conf = OmegaConf.load('/content/configs/okvqa_colab.yaml')\n",
    "model_conf = OmegaConf.load('/content/mmf_transformer_config.yaml')\n",
    "experiment_conf = OmegaConf.load('/content/experiment_config.yaml')\n",
    "extra_args = [\"env.data_dir=/root/.cache/torch/mmf/data/\"]\n",
    "extra_args = OmegaConf.from_dotlist(extra_args)\n",
    "\n",
    "conf = OmegaConf.merge(dataset_conf, model_conf, experiment_conf, extra_args)\n",
    "\n",
    "conf.dataset_config.okvqa_colab.processors.answer_processor.params.vocab_file\\\n",
    "    =\"/root/.cache/torch/mmf/data/datasets/\" \\\n",
    "    + conf.dataset_config.okvqa_colab.processors.answer_processor.params.vocab_file\n",
    "\n",
    "\n",
    "\n",
    "# Build processors\n",
    "mmf_processors = build_processors(conf.dataset_config.okvqa_colab.processors)\n",
    "\n",
    "\n",
    "\n",
    "# Build model\n",
    "model = MMFTransformer(conf.model_config.mmf_transformer)\n",
    "model.build()\n",
    "model.init_losses()\n",
    "\n",
    "state_dict = torch.load('okvqa_mmft.ckpt')\n",
    "model.load_state_dict(state_dict[\"model\"])\n",
    "model.to(\"cuda\")\n",
    "model.eval()\n",
    "print(\"Model Loaded Successfully!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2033ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample(image, text):\n",
    "  # Create a Sample\n",
    "  current_sample = Sample()\n",
    "\n",
    "  # Preprocess the text to generate tokens\n",
    "  processed_text = mmf_processors[\"text_processor\"]({\"text\": text})\n",
    "  current_sample.update(processed_text)\n",
    "  \n",
    "  # Load the image and run image preprocessors on it\n",
    "  current_sample.image = mmf_processors[\"image_processor\"](image)\n",
    "\n",
    "  # Create a sample list\n",
    "  sample_list = SampleList([current_sample])\n",
    "  sample_list = sample_list.to(\"cuda\")\n",
    "  return sample_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b748eb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = \"http://images.cocodataset.org/train2017/000000444444.jpg\" #@param {type:\"string\"}\n",
    "question = \"Which sport requires riding on the animal depicted?\" #@param {type:\"string\"}\n",
    "urllib.request.urlretrieve(image_url, \"/content/local.jpg\")\n",
    "image = tv_helpers.default_loader(\"/content/local.jpg\")\n",
    "print(\"Image :: \\n\")\n",
    "plt.imshow(image)\n",
    "print(\"Question :: \", question)\n",
    "\n",
    "output = model(create_sample(image, question))\n",
    "output = torch.nn.functional.softmax(output[\"scores\"], dim=1)\n",
    "prob, indices = output.topk(1, dim=1)\n",
    "answer = mmf_processors[\"answer_processor\"].idx2word(indices[0][0])\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MMF_Env]",
   "language": "python",
   "name": "conda-env-MMF_Env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
